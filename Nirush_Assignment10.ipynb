{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nirush_Assignment10.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlYVLyoXbPvX",
        "colab_type": "text"
      },
      "source": [
        "# ***Problem Statement 1***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUgrpNjiFQni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "#from sklearn import preprocessing, cross_validation\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_PmUj7oyRe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(123)\n",
        "\n",
        "walks = []\n",
        "\n",
        "for i in range(250):\n",
        "    randomwalk = [0]\n",
        "\n",
        "    for n in range(100):\n",
        "        steps = randomwalk[-1]\n",
        "        dicevalue = np.random.randint(1,7)\n",
        "\n",
        "        if dicevalue <= 2 :\n",
        "            steps = max(0, step - 1)\n",
        "\n",
        "        elif dicevalue<=5:\n",
        "            steps += 1\n",
        "\n",
        "        else:\n",
        "            steps = steps + np.random.randint(1,7)\n",
        "        \n",
        "    print(steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl1m-QB_bfw_",
        "colab_type": "text"
      },
      "source": [
        "# ***Problem Statement 2***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZXYH0qvcrOw",
        "colab_type": "text"
      },
      "source": [
        "Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReY3UU3qzgyE",
        "colab_type": "code",
        "outputId": "828268cc-e560-4103-eea1-26d474e0f733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(1)\n",
        "n_features = 4\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "#print(X)\n",
        "eps = scipy.stats.norm.rvs(0, 0.25,100)\n",
        "y = 1 + (0.4 * X[0]) + eps + (0.5 * X[1]) + (0.3 * X[2]) + (0.4 * X[3])\n",
        "mult_lin_reg = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y }\n",
        "df = pd.DataFrame(mult_lin_reg)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "#df.to_csv('file1.csv')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3         Y\n",
            "0  0.468180 -1.184577  0.668264 -0.361615  0.142081\n",
            "1  0.441103 -0.527508  0.089054  0.911475  1.659761\n",
            "2 -0.236677  0.922560  1.198019 -0.459759  1.126751\n",
            "3 -0.309893 -0.510977  1.400727 -2.122170 -0.023457\n",
            "4 -1.744054  0.303596 -0.567046 -0.356668 -0.198443\n",
            "          X0        X1        X2        X3         Y\n",
            "95 -0.990764 -1.976843 -0.573479 -0.705782 -0.558995\n",
            "96 -1.256584  0.584022 -1.270979  0.639396  0.892662\n",
            "97  0.263987 -1.271284  0.171269  0.416116  0.414388\n",
            "98  0.207852 -0.986270  0.643869 -0.050302  0.633620\n",
            "99  0.348863  1.584008 -0.815188 -0.523906  1.118265\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   X3      100 non-null    float64\n",
            " 4   Y       100 non-null    float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 4.0 KB\n",
            "None\n",
            "               X0          X1          X2          X3           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000  100.000000\n",
            "mean    -0.005721   -0.134997   -0.148583    0.069929    0.918366\n",
            "std      1.038847    0.988391    0.966543    1.029472    0.758284\n",
            "min     -2.115157   -2.908767   -2.081400   -2.526877   -1.086428\n",
            "25%     -0.704911   -0.901174   -0.767689   -0.490009    0.419129\n",
            "50%      0.055964   -0.008466   -0.243833    0.077881    0.940017\n",
            "75%      0.700917    0.537169    0.623344    0.818848    1.481693\n",
            "max      2.126376    1.878365    2.257439    2.575365    2.921781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IOBpSx7duze",
        "colab_type": "text"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhRfGyIbAjqB",
        "colab_type": "code",
        "outputId": "0af8dcac-d280-46bb-e8b7-143f49ce54f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "n_features = 4\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "#print(X)\n",
        "a1 = (np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))/(1 + np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))))\n",
        "#print(a1)\n",
        "y1 = []\n",
        "for i in a1:\n",
        "  if (i>=0.5):\n",
        "    y1.append(1)\n",
        "  else:\n",
        "    y1.append(0)\n",
        "#print(y1)\n",
        "data_lr = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y1 }\n",
        "df1 = pd.DataFrame(data_lr)\n",
        "print(df1.head())\n",
        "print(df1.tail())\n",
        "print(df1.info())\n",
        "print(df1.describe())\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3  Y\n",
            "0  1.110656 -0.772822 -0.709473 -0.481980  1\n",
            "1 -0.965138 -1.913829  0.853713 -1.675209  0\n",
            "2  0.254199  1.299998  0.291412  0.038717  1\n",
            "3 -0.629710  0.923468 -0.712271  2.313977  1\n",
            "4 -0.762620  0.409179 -0.443908  0.964827  1\n",
            "          X0        X1        X2        X3  Y\n",
            "95 -0.144817  0.034351 -1.035277  0.979805  1\n",
            "96 -0.174953  1.760519  0.953670 -0.987525  1\n",
            "97  0.381541  1.199246 -1.211055  1.256834  1\n",
            "98 -0.752687 -0.544136  0.095453  1.482010  1\n",
            "99 -0.189609  0.503176  0.353161  1.154585  1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   X3      100 non-null    float64\n",
            " 4   Y       100 non-null    int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 4.0 KB\n",
            "None\n",
            "               X0          X1          X2          X3           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000  100.000000\n",
            "mean    -0.039590    0.088497    0.065778    0.011757    0.870000\n",
            "std      0.988427    1.048281    1.078176    0.911817    0.337998\n",
            "min     -2.287160   -2.057090   -2.227336   -1.774072    0.000000\n",
            "25%     -0.755170   -0.626176   -0.718832   -0.739439    1.000000\n",
            "50%     -0.108793    0.121977    0.183910   -0.022241    1.000000\n",
            "75%      0.426971    0.797020    0.798318    0.653844    1.000000\n",
            "max      2.981098    3.150811    2.937331    2.402019    1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgfNCjpUfJsz",
        "colab_type": "text"
      },
      "source": [
        "K means Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "187dd6c8-e022-44ba-e39e-ebb189fb3665",
        "id": "G5Z5ClMps7Ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        }
      },
      "source": [
        "X_a= -2 * np.random.rand(100,2)\n",
        "X_b = 1 + 2 * np.random.rand(50,2)\n",
        "X_a[50:100, :] = X_b\n",
        "plt.scatter(X_a[ : , 0], X_a[ :, 1], s = 50)\n",
        "plt.show()\n",
        "data_kmeans = {'X0': X_a[:,0],'X1':X_a[:,1]}\n",
        "df3 = pd.DataFrame(data_kmeans)\n",
        "print(df3.head())\n",
        "print(df3.tail())\n",
        "print(df3.info())\n",
        "print(df3.describe())"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "         X0        X1\n",
            "0 -0.523337 -1.393898\n",
            "1 -1.318225 -1.115967\n",
            "2 -0.218680 -0.933621\n",
            "3 -0.952209 -1.397683\n",
            "4 -1.920370 -0.083036\n",
            "          X0        X1\n",
            "95  2.192850  2.720248\n",
            "96  2.955778  1.467187\n",
            "97  2.300942  1.533330\n",
            "98  2.529914  2.180660\n",
            "99  2.259825  2.741467\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 1.7 KB\n",
            "None\n",
            "               X0          X1\n",
            "count  100.000000  100.000000\n",
            "mean     0.607762    0.526345\n",
            "std      1.595606    1.616804\n",
            "min     -1.950776   -1.955224\n",
            "25%     -0.778325   -1.008783\n",
            "50%      0.521813    0.521788\n",
            "75%      2.167180    2.019584\n",
            "max      2.955778    2.954341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddLy-bxGf5nJ",
        "colab_type": "text"
      },
      "source": [
        "# ***Problem Statement 3***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOXDvXNxgRkJ",
        "colab_type": "text"
      },
      "source": [
        "LinearRegression using Gradient Descent "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa3knLkqGTZv",
        "colab_type": "code",
        "outputId": "1a3e310d-5dc9-4616-93c9-719234bbaeda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2\n",
        "  d1 = (-2/n) * sum(X * (y - y_p))\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08297726333408594 0.18006939723867305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSFyQvpRj_fC",
        "colab_type": "text"
      },
      "source": [
        "LogisticRegression using Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkzDhVrZZ6rq",
        "colab_type": "code",
        "outputId": "75b89610-2bd6-467f-e751-a8797003d6e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz)\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.47096204385178514\n",
            "0.47054237553426564\n",
            "0.47013414238054446\n",
            "0.4697370157664569\n",
            "0.4693506770579072\n",
            "0.46897481730403745\n",
            "0.4686091369370541\n",
            "0.46825334547910435\n",
            "0.4679071612564996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1usGox2lYoQ",
        "colab_type": "text"
      },
      "source": [
        "LinearRegression using L1 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h29KsbGVpGYF",
        "colab_type": "code",
        "outputId": "41e6217c-1e0e-4d1a-b19a-054b3b1f22b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + (lam * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + lam\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0738712823591653 0.18008044130900397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrWMefG8pVEn",
        "colab_type": "text"
      },
      "source": [
        "LinearRegression using L2 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQRD15PuqENj",
        "colab_type": "code",
        "outputId": "f14e67ca-fb40-4181-ed95-4e2cddf99e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + ((lam/2) * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + (lam *b1)\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08257998381739863 0.1800697210778034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN9v5RgUlrov",
        "colab_type": "text"
      },
      "source": [
        "LogisticRegression usign L1 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqr8pUh8rJ0A",
        "colab_type": "code",
        "outputId": "eb717526-bf0e-46da-a5c4-fa7e2784f530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(W)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "-0.0957178147843501\n",
            "-0.49126928267553843\n",
            "-0.8838759664840703\n",
            "-1.2735829336825866\n",
            "-1.660434584454674\n",
            "-2.044474635211784\n",
            "-2.4257461061958714\n",
            "-2.804291312728332\n",
            "-3.1801518596965117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3N4A12utU0p",
        "colab_type": "text"
      },
      "source": [
        "LogisticRegression using L2 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYOUM896rrsz",
        "colab_type": "code",
        "outputId": "0727a761-73f0-4214-ea40-4487aad93c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(np.square(W))))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam * W\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.30253765266491595\n",
            "0.30260591111172064\n",
            "0.30273910226152506\n",
            "0.30293387149915413\n",
            "0.3031870022514592\n",
            "0.30349541047524015\n",
            "0.30385613937861167\n",
            "0.30426635436466415\n",
            "0.30472333818688496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1qb7-7KtgbU",
        "colab_type": "text"
      },
      "source": [
        "K means Clustering Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdkxTDkgEMDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpLrjR_OiXo3",
        "colab_type": "code",
        "outputId": "a32dbe31-15d4-4747-82fd-8742e7abf1b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "X = df3.iloc[:,0:2].values\n",
        "clf = K_Means()\n",
        "clf.fit(X)\n",
        "\n",
        "for centroid in clf.centroids:\n",
        "    plt.scatter(clf.centroids[centroid][0], clf.centroids[centroid][1],\n",
        "                marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
        "\n",
        "for classification in clf.classifications:\n",
        "    color = colors[classification]\n",
        "    for featureset in clf.classifications[classification]:\n",
        "        plt.scatter(featureset[0], featureset[1], marker=\"x\", color=color, s=150, linewidths=5)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "155.2251271407831\n",
            "167.0476488109652\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POH9C8wAtst_",
        "colab_type": "text"
      },
      "source": [
        "# ***Problem Statement 4***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRKsiCuftxeA",
        "colab_type": "text"
      },
      "source": [
        "LinearRegression using OOPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSZVP0_zu9QS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class LinearRegressionModel():\n",
        "\n",
        "    def __init__(self, dataset, learning_rate, num_iterations):\n",
        "        self.dataset = np.array(dataset)\n",
        "        self.b = 0  \n",
        "        self.m = 0  \n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.M = len(self.dataset)\n",
        "        self.total_error = 0\n",
        "\n",
        "    def apply_gradient_descent(self):\n",
        "        for i in range(self.num_iterations):\n",
        "            self.do_gradient_step()\n",
        "\n",
        "    def do_gradient_step(self):\n",
        "        b_summation = 0\n",
        "        m_summation = 0\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            b_summation += (((self.m * x_value) + self.b) - y_value) \n",
        "            m_summation += (((self.m * x_value) + self.b) - y_value) * x_value\n",
        "        self.b = self.b - (self.learning_rate * (1/self.M) * b_summation)\n",
        "        self.m = self.m - (self.learning_rate * (1/self.M) * m_summation)\n",
        "      \n",
        "    def compute_error(self):\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            self.total_error += ((self.m * x_value) + self.b) - y_value\n",
        "        return self.total_error\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Results: b: {}, m: {}, Final Total error: {}\".format(round(self.b, 2), round(self.m, 2), round(self.compute_error(), 2))\n",
        "\n",
        "    def get_prediction_based_on(self, x):\n",
        "        return round(float((self.m * x) + self.b), 2) \n",
        "\n",
        "def main():\n",
        "    school_dataset = np.genfromtxt(DATASET_PATH, delimiter=\",\")\n",
        "    lr = LinearRegressionModel(school_dataset, 0.0001, 1000)\n",
        "    lr.apply_gradient_descent()\n",
        "    hours = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "    for hour in hours:\n",
        "        print(\"Studied {} hours and got {} points.\".format(hour, lr.get_prediction_based_on(hour)))\n",
        "    print(lr)\n",
        "    if __name__ == \"__main__\": main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWA9pLsnvFAJ",
        "colab_type": "text"
      },
      "source": [
        "LogisticRegression using OOPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljHZlX41txID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression:\n",
        "  def __init__(self, learning_rate, num_iters, fit_intercept = True, verbose = False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iters = num_iters\n",
        "    self.fit_intercept = fit_intercept\n",
        "    self.verbose = verbose\n",
        "  def __add_intercept(self, X):\n",
        "    intercept = np.ones((X.shape[0],1))\n",
        "    return np.concatenate((intercept,X),axis=1)\n",
        "  def __sigmoid(self,z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "  def __loss(self, h, y):\n",
        "    return (-y * np.log(h) - (1-y) * np.log(1-h)).mean()\n",
        "  \n",
        "  def fit(self,X,y):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    self.theta = np.zeros(X.shape[1])\n",
        "    \n",
        "    for i in range(self.num_iters):\n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      gradient = np.dot(X.T,(h-y))/y.size\n",
        "      \n",
        "      self.theta -= self.learning_rate * gradient\n",
        "      \n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      loss = self.__loss(h,y)\n",
        "      \n",
        "      if self.verbose == True and i % 1000 == 0:\n",
        "        print(f'Loss: {loss}\\t')\n",
        "  def predict_probability(self,X):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    return self.__sigmoid(np.dot(X,self.theta))\n",
        "  def predict(self,X):\n",
        "    return (self.predict_probability(X).round())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC71PHtavKS5",
        "colab_type": "text"
      },
      "source": [
        "K means using OOPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuBU7YY_t90Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}